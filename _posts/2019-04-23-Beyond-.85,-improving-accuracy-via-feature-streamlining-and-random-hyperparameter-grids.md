---
layout: post
title: "Beyond .85, improving accuracy via feature streamlining and random hyperparameter grids"
date: 2019-04-23
---

A random forests algorithm applied to Lending Club data predicted default rates with .85 accuracy out of the box. Could streamlining the feature set from an initial 40, and randomly sampling grids of hyperparameter values, maintain or improve that accuracy?

This is an extensive example of my work on a data science project, soup to nuts. To see the answer to the question above, copy and paste the link below. 

http://bit.ly/RBPHD_beyond85
