---
layout: post
title: "Text classification via naive Bayes, logistic regression, SVM, and with tf-idf vectorization"
date: 2018-09-17
---

This started out as an exercise on naive Bayes for text classification. Using the data provided (text for reviews on rottentomatoes.com and the reviews' fresh or not designation, i.e., the text classification), I instead explored some related methods I was interested in, specifically:

1. Implementing text normalization and preprocessing
2. Comparing outcomes from several text classification models (naive Bayes, logistic rgression, and support vector machines)
3. And doing so with and without term-frequency/inverse document frequency (TF-IDF) vectorization

Cut and paste the link below to see they Jupyter notebook. Once there, if you want to see the histograms in plotly click the theta symbol at the top right.

https://github.com/RossBrownPhD/Work_Samples_and_Resume/blob/master/09_Text_classification_via_naive_Bayes%2C_logistic_regression%2C_SVM%2C_and_tf-idf.ipynb
